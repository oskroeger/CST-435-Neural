{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Import the Zalando dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-09-29T19:45:55.630970Z",
     "start_time": "2023-09-29T19:45:36.322633Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/train-labels-idx1-ubyte.gz\n",
      "29515/29515 [==============================] - 0s 1us/step\n",
      "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/train-images-idx3-ubyte.gz\n",
      "26421880/26421880 [==============================] - 4s 0us/step\n",
      "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/t10k-labels-idx1-ubyte.gz\n",
      "5148/5148 [==============================] - 0s 0us/step\n",
      "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/t10k-images-idx3-ubyte.gz\n",
      "4422102/4422102 [==============================] - 2s 1us/step\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.datasets import fashion_mnist\n",
    "import numpy as np\n",
    "\n",
    "((trainX, trainY), (testX, testY)) = fashion_mnist.load_data()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "prepare the data (reshaping the samples and one-hot encoding the labels):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-09-29T19:46:06.509097Z",
     "start_time": "2023-09-29T19:46:06.505015Z"
    }
   },
   "outputs": [],
   "source": [
    "labels_train = np.zeros((60000, 10))\n",
    "labels_train[np.arange(60000), trainY] = 1\n",
    "data_train = trainX.reshape(60000, 28, 28, 1)\n",
    "\n",
    "labels_test = np.zeros((10000, 10))\n",
    "labels_test[np.arange(10000), testY] = 1\n",
    "data_test = testX.reshape(10000, 28, 28, 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that in this case, we use as network’s inputs tensors of dimensions\n",
    "(number_of_images, image_height, image_width, color_channels). Since the\n",
    "Zalando dataset is made up of gray values images, the color_channels will be equal to 1.\n",
    "Each observation is in a row (since feed-forward neural networks take as input flattened\n",
    "tensors). Check the dimensions with the code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-09-29T19:46:42.413836Z",
     "start_time": "2023-09-29T19:46:42.408708Z"
    },
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dimensions of the training dataset:  (60000, 28, 28, 1)\n",
      "Dimensions of the test dataset:  (10000, 28, 28, 1)\n",
      "Dimensions of the training labels:  (60000, 10)\n",
      "Dimensions of the test labels:  (10000, 10)\n"
     ]
    }
   ],
   "source": [
    "print('Dimensions of the training dataset: ', data_train.shape)\n",
    "print('Dimensions of the test dataset: ', data_test.shape)\n",
    "print('Dimensions of the training labels: ', labels_train.shape)\n",
    "print('Dimensions of the test labels: ', labels_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Normalize the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-09-29T19:46:56.174123Z",
     "start_time": "2023-09-29T19:46:56.018736Z"
    }
   },
   "outputs": [],
   "source": [
    "data_train_norm = np.array(data_train / 255.0)\n",
    "data_test_norm = np.array(data_test / 255.0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Build our network. With Keras, creating and training a CNN\n",
    "model is straightforward; the following function defines the network’s architecture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-09-29T19:50:01.107110Z",
     "start_time": "2023-09-29T19:50:01.102793Z"
    }
   },
   "outputs": [],
   "source": [
    "from tensorflow.keras import models, layers\n",
    "\n",
    "\n",
    "def build_model():\n",
    "\t# create model\n",
    "\tmodel = models.Sequential()\n",
    "\tmodel.add(layers.Conv2D(6, (5, 5), strides=(1, 1),\n",
    "\t                        activation='relu',\n",
    "\t                        input_shape=(28, 28, 1)))\n",
    "\tmodel.add(layers.MaxPooling2D(pool_size=(2, 2),\n",
    "\t                              strides=(2, 2)))\n",
    "\tmodel.add(layers.Conv2D(16, (5, 5), strides=(1, 1),\n",
    "\t                        activation='relu'))\n",
    "\tmodel.add(layers.MaxPooling2D(pool_size=(2, 2),\n",
    "\t                              strides=(2, 2)))\n",
    "\tmodel.add(layers.Flatten())\n",
    "\tmodel.add(layers.Dense(128, activation='relu'))\n",
    "\tmodel.add(layers.Dense(10, activation='softmax'))\n",
    "\t# compile model\n",
    "\tmodel.compile(loss='categorical_crossentropy',\n",
    "\t              optimizer='adam',\n",
    "\t              metrics=['categorical_accuracy'])\n",
    "\treturn model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When building CNNs in Keras, a single line of code (and a Keras method) will\n",
    "correspond to a different layer. The build_model function creates a CNN stacking Conv2D\n",
    "(which builds a convolutional layer) and MaxPooling2D (which builds a max pooling\n",
    "layer) layers. The stride is a tuple since it gives the stride in different dimensions (for\n",
    "rows and columns). In our examples we have gray images, but we could also have RGB,\n",
    "for example. That would mean having more dimensions: the three color channels.\n",
    "\n",
    "Display the architecture of the model so far, using model.summary():"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-09-29T19:50:11.804169Z",
     "start_time": "2023-09-29T19:50:11.739836Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d (Conv2D)             (None, 24, 24, 6)         156       \n",
      "                                                                 \n",
      " max_pooling2d (MaxPooling2D  (None, 12, 12, 6)        0         \n",
      " )                                                               \n",
      "                                                                 \n",
      " conv2d_1 (Conv2D)           (None, 8, 8, 16)          2416      \n",
      "                                                                 \n",
      " max_pooling2d_1 (MaxPooling  (None, 4, 4, 16)         0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " flatten (Flatten)           (None, 256)               0         \n",
      "                                                                 \n",
      " dense (Dense)               (None, 128)               32896     \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 10)                1290      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 36,758\n",
      "Trainable params: 36,758\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = build_model()\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that the output of every convolutional and pooling layer is a 3D tensor of\n",
    "shape (height, width, number_of_filters). The first dimension (i.e., the number of\n",
    "batches), is set to None since the network does not know it yet and thus it can be applied\n",
    "to every set of samples, of any length. The width and height dimensions decrease as you\n",
    "go deeper into the network. The number of output channels for each Conv2D layer is\n",
    "controlled by the first function argument. Typically, as the width and height decrease,\n",
    "you can afford (computationally) to add more output filters to each Conv2D layer."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To complete the model, we added two Dense layers. They take vectors as input\n",
    "(which are 1D), while the current output is a 3D tensor. This is why you first need to\n",
    "flatten the 3D output to 1D, then add one or more Dense layers on top."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Train and test the network. Use mini-batch gradient descent\n",
    "with a batch size of 100 and we will train our network for ten epochs."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you run this code (it took roughly four minutes on a medium performance laptop),\n",
    "it will start, after just one epoch, with a training accuracy of 76.3%. After ten epochs it will\n",
    "reach a training accuracy of 91% (88% on the dev set)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-09-29T19:51:23.387018Z",
     "start_time": "2023-09-29T19:50:44.110769Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "  1/600 [..............................] - ETA: 1:34 - loss: 2.3344 - categorical_accuracy: 0.0600"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-09-29 12:50:44.176152: W tensorflow/core/platform/profile_utils/cpu_utils.cc:128] Failed to get CPU frequency: 0 Hz\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "600/600 [==============================] - 4s 7ms/step - loss: 0.6655 - categorical_accuracy: 0.7639 - val_loss: 0.5253 - val_categorical_accuracy: 0.8115\n",
      "Epoch 2/10\n",
      "600/600 [==============================] - 4s 7ms/step - loss: 0.4365 - categorical_accuracy: 0.8443 - val_loss: 0.4348 - val_categorical_accuracy: 0.8433\n",
      "Epoch 3/10\n",
      "600/600 [==============================] - 4s 7ms/step - loss: 0.3861 - categorical_accuracy: 0.8615 - val_loss: 0.3815 - val_categorical_accuracy: 0.8654\n",
      "Epoch 4/10\n",
      "600/600 [==============================] - 4s 6ms/step - loss: 0.3566 - categorical_accuracy: 0.8736 - val_loss: 0.3547 - val_categorical_accuracy: 0.8717\n",
      "Epoch 5/10\n",
      "600/600 [==============================] - 4s 6ms/step - loss: 0.3304 - categorical_accuracy: 0.8814 - val_loss: 0.3480 - val_categorical_accuracy: 0.8738\n",
      "Epoch 6/10\n",
      "600/600 [==============================] - 4s 7ms/step - loss: 0.3161 - categorical_accuracy: 0.8854 - val_loss: 0.3394 - val_categorical_accuracy: 0.8778\n",
      "Epoch 7/10\n",
      "600/600 [==============================] - 4s 6ms/step - loss: 0.3026 - categorical_accuracy: 0.8905 - val_loss: 0.3286 - val_categorical_accuracy: 0.8827\n",
      "Epoch 8/10\n",
      "600/600 [==============================] - 4s 6ms/step - loss: 0.2897 - categorical_accuracy: 0.8953 - val_loss: 0.3212 - val_categorical_accuracy: 0.8822\n",
      "Epoch 9/10\n",
      "600/600 [==============================] - 4s 6ms/step - loss: 0.2781 - categorical_accuracy: 0.8993 - val_loss: 0.3131 - val_categorical_accuracy: 0.8890\n",
      "Epoch 10/10\n",
      "600/600 [==============================] - 4s 7ms/step - loss: 0.2691 - categorical_accuracy: 0.9017 - val_loss: 0.3112 - val_categorical_accuracy: 0.8878\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x167ae6440>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(data_train_norm, labels_train, validation_data= (data_test_norm, labels_test), epochs=10, batch_size=100, verbose=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Try to change the network’s parameters to see if you can get a better accuracy. \n",
    "Change kernel size, stride, and padding."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
